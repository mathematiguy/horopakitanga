{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04bd45c-e0ab-453f-a1bc-b59ae6486687",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "Now that we have a model trained that seems to have learned well, we can examine it to see how well it really learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7b0908-d35e-4ac0-a055-77b6d2a0a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ataarangi.train import TransformerModel\n",
    "from ataarangi.data import TextTokenizer, WorldStateTokenizer, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be777b68-ed2b-4642-ad2c-491740e6db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizers\n",
    "world_state_tokenizer = WorldStateTokenizer('../data/worldstate_tokens.txt')\n",
    "text_tokenizer = TextTokenizer('../data/tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879bc3f9-4644-4fe0-a30a-27be4dc2709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<SOS>': 1,\n",
       " '<SELECTED>': 2,\n",
       " '<NOT_SELECTED>': 3,\n",
       " 'color_red': 4,\n",
       " 'color_blue': 5,\n",
       " 'color_green': 6,\n",
       " 'color_yellow': 7,\n",
       " 'color_black': 8,\n",
       " 'color_white': 9,\n",
       " 'color_brown': 10,\n",
       " 'color_pink': 11,\n",
       " 'height_1': 12,\n",
       " 'height_2': 13,\n",
       " 'height_3': 14,\n",
       " 'height_4': 15,\n",
       " 'height_5': 16,\n",
       " 'height_6': 17,\n",
       " 'height_7': 18,\n",
       " 'height_8': 19,\n",
       " 'height_9': 20,\n",
       " 'height_10': 21,\n",
       " '<CLS>': 22}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_state_tokenizer.token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce9bde4-82e8-4477-bab5-a39cb53ac426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rākau': 23,\n",
       " 'te': 24,\n",
       " 'ngā': 25,\n",
       " 'me': 26,\n",
       " 'mā': 27,\n",
       " 'kākāriki': 28,\n",
       " 'kōwhai': 29,\n",
       " 'kikorangi': 30,\n",
       " 'parauri': 31,\n",
       " 'pango': 32,\n",
       " 'whero': 33,\n",
       " 'māwhero': 34,\n",
       " 'iti': 35,\n",
       " 'nui': 36,\n",
       " 'hāunga': 37,\n",
       " 'katoa': 38,\n",
       " 'rawa': 39,\n",
       " 'taha': 40,\n",
       " 'kei': 41,\n",
       " 'mauī': 42,\n",
       " 'matau': 43,\n",
       " 'ki': 44,\n",
       " 'tawhiti': 45,\n",
       " 'e': 46,\n",
       " 'rua': 47,\n",
       " 'waenganui': 48,\n",
       " 'i': 49,\n",
       " 'toru': 50,\n",
       " 'tuarua': 51,\n",
       " 'mai': 52,\n",
       " '[END]': 53}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6439038f-e366-4ae4-b4d2-b53176c114e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, params):\n",
    "    model = TransformerModel(**params)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "best_model_params = {\n",
    "    'vocab_size': 54,\n",
    "    'embed_size': 256,\n",
    "    'nhead': 4,\n",
    "    'num_encoder_layers': 3,\n",
    "    'num_decoder_layers': 3,\n",
    "    'dim_feedforward': 1024,\n",
    "    'max_seq_length': 500,\n",
    "    'dropout': 0.17962795808108917\n",
    "}\n",
    "\n",
    "best_model = load_model(\n",
    "    '../models/lr=0.0003-num_layers=3-embed_size=256-nhead=4-dim_ff=1024-dropout=0.1796.pth',\n",
    "    best_model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec6e73bd-aad2-4228-bc29-a5fa78bd64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = load_data('../data/train_set.csv', '../data/dev_set.csv', text_tokenizer, world_state_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02c1046-c1d4-43e4-81bf-4d96932eaa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 53])\n"
     ]
    }
   ],
   "source": [
    "tokens = world_state_tokenizer.tokenize(train_data['rākau'][0])\n",
    "tokens_tensor = torch.tensor(tokens, dtype=torch.long)  # Ensure the tensor is of type long\n",
    "generated_sequence = best_model.generate(tokens_tensor)\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f879b0d7-b135-4fd5-bd09-32db457c7b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43m[\u001b[49m\u001b[43mtext_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerated_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mtext_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m generated_sequence\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m2\u001b[39m:]])\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "' '.join([text_tokenizer.id_map[tok] for tok in generated_sequence.cpu().tolist()[2:]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
