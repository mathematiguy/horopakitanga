\subsection{World state generation}

The world states under consideration in this task are referred to as ``contexts''. Each context comprises of a sequence of randomly chosen cuisenaire rods, each of which have a given colour (chosen from a set of 8) and length (ranging from 1-10). A context can have up to 13 rods, and from the context a random subset is selected.

The goal of the task is to write an utterance which correctly identifies the selected rods from among the rest in the context. This problem was constructed to be similar to a typical first language lesson according to the Te Ataarangi method.

Sampling uniformly from a large world state space would result in a large proportion of states with high entropy. This would be undesirable, since the goal is to teach the language so we chose to start from simpler world states and gradually increase the complexity. For that reason, we used the following procedure to generate arrangements of cuisenaire rods:

\begin{itemize}
\item An entropy budget is decided in advance. This entropy is computed as the sum of the entropy of the colour and height.
\item A rod is then drawn, with random height and colour.
\item The entropy of the current configuration including the new rod.
\item If it is above the threshold, then end otherwise add another rod.
\end{itemize}

\subsection{Labelling world states}

During labelling, the entropy budget begins set to 0.5, and then every 66 examples the budget was increased by 0.5 to a cap of 8.0 resulting in a sample size of 990. For certain easy cases, such as when all rods are selected, a pre-computed utterance such as ``ngā rākau katoa'' (``all of the rods'') or ``te rākau'' (``the rod'') would automatically be entered on behalf of the user. This happened in approximately 30\% of the examples in the dataset.

\subsection{Conversational Agents}

In this work, we aim to implement a pair of conversational agents. A teacher $A_{teacher}$, and a student $A_{student}$. The agents comprise of two models, the first maps contexts to utterances. In the case of the teacher, this model is pre-trained to be correct, while the student begins with a randomly initialised model.

The second model is designed to suggest world states for demonstration. For the teacher, this functions as a curriculum that takes in the history of (context, utterance) pairs from the student, and suggests world states that will help the student arrive at correct conclusions. In the case of the student, the world states are chosen to demonstrate that it has acquired the ability to produce correct utterances for the kinds of world states that the teacher has demonstrated so far, as well as to make conjectures that will demonstrate that the patterns it has learned generalise in the right way.

\subsection{The dataset}



\subsection{Models}

\subsection{The experiments}
