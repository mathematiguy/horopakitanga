\subsection{Scalar implicature}

% What is the functional role of scalar implicature in this task?
Scalar implicature \cite{grice1975logic} is a fundamental problem class for any language learning system. As such, learning a new language involves solving implicature tasks of a range of types, in increasing complexity. While not sufficient on its own, mastering scalar implicature will teach a student about grammar, vocab and syntax that are common in everyday life. It is clear that in order for a conversational agent to be an effective teacher, it first must have a mastery of the target task.

The task of learning natural language quantifiers from abstracted world states was investigated in \cite{sorodoc2016look}, where the authors trained and tested whether neural networks were able to learn natural language quantifiers such as \textit{no}, \textit{some} and \textit{all}. In their task, the model was trained on images containing 1-16 circles of up to 15 different colours. They generated all possible colourings in their dataset. They compared an RNN with a quantised memory network (qMN) and found that the latter outperformed the RNN with a model accuracy of 88.8\% on familiar examples vs 65.7\% for the RNN.

In \cite{zheng2021grice} the authors prepare a dataset of sample dialogues, where implicature is present, and models are then trained in order to resolve the implicature to an explicit form by answering targeted questions constructed based on the sample dialogue. This bears some resemblance to the language instruction problem, in the sense that the question-answer pairs are given after a dialogue in order to check understanding. The formulation of the $n$-round dialogue as a sequence of QA-pairs $\{(Q_1, A_1), (Q_2, A_2), \cdots, (Q_n, A_n)\}$, where $Q_i$ is the question raised by the first agent, and $A_i$ is the response provided by the second agent, which may contain an implicature. The dataset contains 15,000 dialogues, where 6,000 were used for training, 4,000 for development and 5,000 for testing. This is considerably more than the dataset we are currently using, and also the dialogues are quite rich and varied, as compared to ours which focus on a very specific task.

\subsection{Dialogue agents}

% What is the functional role of dialogue agents in this task?
Dialogue agents are often envisioned as a method for teaching new information. However, to convey information well it is necessary for a model to know when the information has been acquired by the target or not. This is a necessary part of teaching to any kind of curriculum. So the purpose of our use of dialogue agents in this paper is to track the progress of the student and make recommendations about what they need to learn next.

Previous work has trained rational pragmatic models for correctly generating and following natural language instructions for complex tasks \cite{fried2017unified}. Indeed, sequential language games \cite{khani2018planning} have been explored using training data acquired via Amazon Mechanical-Turk. Personality modelling \cite{yang2020improving} is related to our goal task because it is necessary for the teacher to have an implicit model of the student's progress in order to make sensible world state recommendations. Other work has focused on making agents that communicate with humans in natural language \cite{lazaridou2020multi}.

\subsection{Under-resourced language modelling}

Low resource language work in pragmatics often uses the term ``low-resource'' to refer to ``not having a lot of data'' as opposed to data from or relating to under-resourced language communities. In this way, there are a lot of low-resource works that have little resemblance to work on language revitalisation. Some work has focused on implementing pragmatic reasoning under computational constraints \cite{van2020simple}, which the authors referred to ``frugal pragmatism''. This gap in the literature may reflect the fact that many under-resourced languages have yet to acquire models which are powerful enough to demonstrate strong pragmatic capabilities.

In some ways, many of the well known pragmatics problems are readily expressed in English as well as in other languages, and so to keep the work accessible to the largely English speaking research community, it makes sense that pragmatics work in other languages is still quite rare. Perhaps relatedly, a large proportion of the under-resourced language language modelling work focuses on translation compared to solving task specific goals like question-answering. Generally speaking, the goal appears to be to translate out of the under-resourced language into a high resource language like English, and then to do any question-answering or other complex tasks in the high resource language, before translating it back.
