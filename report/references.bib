@inproceedings{diplomacy,
    title = "Linguistic Harbingers of Betrayal: A Case Study on an Online Strategy Game",
    author = "Niculae, Vlad  and
      Kumar, Srijan  and
      Boyd-Graber, Jordan  and
      Danescu-Niculescu-Mizil, Cristian",
    editor = "Zong, Chengqing  and
      Strube, Michael",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1159",
    doi = "10.3115/v1/P15-1159",
    pages = "1650--1659",
}

@inproceedings{mafia,
    title = "Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia",
    author = "Ibraheem, Samee  and
      Zhou, Gaoyue  and
      DeNero, John",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.11",
    doi = "10.18653/v1/2022.naacl-main.11",
    pages = "158--168",
    abstract = "While neural networks demonstrate a remarkable ability to model linguistic content, capturing contextual information related to a speaker{'}s conversational role is an open area of research. In this work, we analyze the effect of speaker role on language use through the game of Mafia, in which participants are assigned either an honest or a deceptive role. In addition to building a framework to collect a dataset of Mafia game records, we demonstrate that there are differences in the language produced by players with different roles. We confirm that classification models are able to rank deceptive players as more suspicious than honest ones based only on their use of language. Furthermore, we show that training models on two auxiliary tasks outperforms a standard BERT-based text classification approach. We also present methods for using our trained models to identify features that distinguish between player roles, which could be used to assist players during the Mafia game.",
}

@inproceedings{enron_deception_keila,
  title={Detecting Unusual and Deceptive Communication in Email},
  author={P. S. Keila and David B. Skillicorn},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:11776080}
}

@inproceedings{enron_deception_gupta,
author = {Gupta, S. and Skillicorn, D. B.},
title = {Improving a Textual Deception Detection Model},
year = {2006},
publisher = {IBM Corp.},
address = {USA},
url = {https://doi.org/10.1145/1188966.1189005},
doi = {10.1145/1188966.1189005},
abstract = {In intelligence, law enforcement, and, increasingly, organizational settings there is interest in detecting deception; for example, in intercepted phone calls, emails, and web sites. Humans are not naturally good at detecting deception, but recent work has shown that deception is actually readily detectable - using markers that humans don't see but which software can readily compute. Pennebaker's model suggests that deceptive communication is characterized by changes in the frequency of four kinds of words: first-person pronouns, exception words, negative emotion words, and action words.We investigate what can be learned about the deception model by applying it to a large corpus of Enron emails. We show that each of the four kinds of words in the Pennebaker model acts as a separate latent factor for deception, rather than having their effects mixed together.},
booktitle = {Proceedings of the 2006 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {29–es},
location = {Toronto, Ontario, Canada},
series = {CASCON '06}
}

@Article{hubris,
    author={Eckhaus, Eyal
    and Sheaffer, Zachary},
    title={Managerial hubris detection: the case of Enron},
    journal={Risk Management},
    year={2018},
    month={11},
    day={01},
    volume={20},
    number={4},
    pages={304-325},
    abstract={Hubris is a known risk for leadership failure. We show that hubristic tendencies can be detected semantically ex-ante in textual reports, and offer a novel methodology aimed at detecting real-time hubristic propensities. The methodology employs text mining based on natural language processing (NLP) on Enron email corpus. NLP can capture information about employees and predict change patterns. Employing NLP real-time mechanism, Enron executives' hubristic tendencies were detected. Findings indicate that hubristic expressions amongst senior executives are significantly more frequent than amongst their non-senior counterparts, and that the frequency of hubristic expressions increases the closer one gets to Enron's collapse. Whilst both Enron's CEO's were hubristic, we found Skilling to be typified with severer hubris. Our study is the first to employ NLP real-time analytical process to detect the hubris disposition. Predicated on Enron's case study, we demonstrate the methodology's strengths, notably immediate recognition of accumulated symptoms and prevalence.},
    issn={1743-4637},
    doi={10.1057/s41283-018-0037-0},
    url={https://doi.org/10.1057/s41283-018-0037-0}
}

@online{enron_dataset,
    organization = {Carnegie Mellon University},
    title = {Enron Email Dataset},
    author = {William W. Cohen},
    month = {5},
    year = {2015},
    url = {https://www.cs.cmu.edu/~enron/}
}

@online{enron_financial_dataset,
    title = {Applying Machine Learning for fraud detection in the Enron financial dataset},
    author = {Ricardo Fideles},
    month = {12},
    year = {2023},
    url = {https://github.com/RicardoFideles/Applying-Machine-Learning-for-fraude-detection-in-the-Enron-financial-dataset/tree/master}
}

@online{nytimes,
    author = {{New York Times}},
    title = {Enron Scorecard},
    organization = {New York Times},
    month = {10},
    year = {2006},
    url = {https://archive.nytimes.com/www.nytimes.com/packages/html/national/20061023_ENRON_TABLE/index.html}
}

@article{sentimentModel,
    title = {More than a Feeling: Accuracy and Application of Sentiment Analysis},
    journal = {International Journal of Research in Marketing},
    volume = {40},
    number = {1},
    pages = {75-87},
    year = {2023},
    doi = {https://doi.org/10.1016/j.ijresmar.2022.05.005},
    url = {https://www.sciencedirect.com/science/article/pii/S0167811622000477},
    author = {Jochen Hartmann and Mark Heitmann and Christian Siebert and Christina Schamp},
}

@misc{enron2015email,
  title        = {Enron Email Dataset},
  author       = {{Enron Corp} and Cohen, William W.},
  year         = 2015,
  howpublished = {United States Federal Energy Regulatory Commission},
  publisher    = {William W. Cohen, Machine Learning Department, Carnegie Mellon University},
  address      = {Philadelphia, PA},
  note         = {[Software, E-Resource]},
  url          = {https://www.loc.gov/item/2018487913/},
}

@article{status-politeness,
  author={Yi Wang},
  title={{The price of being polite: politeness, social status, and their joint impacts on community Q\&A efficiency}},
  journal={Journal of Computational Social Science},
  year=2021,
  volume={4},
  number={1},
  pages={101-122},
  month={May},
  keywords={Online Q\&A community; Politeness; Social status; Power; Social norm; Community enforcement; Communit},
  doi={10.1007/s42001-020-00068-},
  abstract={ Sociolinguistics and computational linguistics literature have revealed negative correlations between social status and politeness in interpersonal conversations. In this article, we took a step further to uncover how social status and politeness interact with each other to jointly impact the efficiency of the Q\&A process in online social Q\&A communities. Using the data collected from two communities of Stack Exchange, we demonstrated that both social status and politeness had significant impacts to determine the efficiency of receiving acceptable answers. Moreover, while low-status users benefited from wording their questions more politely, high-status users were slightly “punished” for being too polite, particular in professional Q\&A communities. However, social status and politeness were not significantly relevant to whether a question could be eventually answered. In general, the social Q\&A process provides the conditions necessary for the manifestation of “offline” social norms. That is: individuals are still being rewarded for behaving correctly according to their social roles, no matter explicitly or implicitly. We discuss the theoretical and practical implications of this study.},
  url={https://ideas.repec.org/a/spr/jcsosc/v4y2021i1d10.1007_s42001-020-00068-7.html}
}


@online{fortune,
    title = {Is Enron Overpriced?},
    organization = {Fortune. CNNMoney.com},
    month = {3},
    year = {2001},
    url = {https://money.cnn.com/2006/01/13/news/companies/enronoriginal_fortune/index.htm},
    author = {McLean, Bethany},
}



@online{andersen-docs,
    title = {ENRON'S COLLAPSE: THE AUDITOR},
    organization = {New York Times},
    month = {1},
    year = {2002},
    author = {Kurt Eichenwald and Floyd Norris},
    url = {https://www.nytimes.com/2002/01/11/business/enron-s-collapse-the-auditor-enron-s-auditor-says-it-destroyed-documents.html}
}

%%%% Enron timeline and stock price -- investopedia
@online{enron-stock,
    title = {Enron Scandal: The Fall of a Wall Street Darling},
    organization = {Investopedia},
    month = {4},
    year = {2023},
    author = {Troy Segal}, 
    url = {https://www.investopedia.com/updates/enron-scandal-summary/}
}